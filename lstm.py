# -*- coding: utf-8 -*-
"""lstm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1bPJLSouUYYb7cqpMXGproDoee-XFyw
"""

!pip install tensorflow numpy pandas matplotlib scikit-learn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.optimizers import Adam

import tensorflow as tf
import numpy as np
import pandas as pd
import sklearn
import matplotlib.pyplot as plt

print("‚úì TensorFlow version:", tf.__version__)
print("‚úì NumPy version:", np.__version__)
print("‚úì Pandas version:", pd.__version__)
print("‚úì Scikit-learn version:", sklearn.__version__)
print("\nAll libraries are ready!")

from google.colab import files
import zipfile
import os

print("Click 'Choose Files' and upload your zip file...")
uploaded = files.upload()

# Get the zip filename
zip_filename = list(uploaded.keys())[0]
print(f"\n‚úì Uploaded: {zip_filename}")

# Extract the zip file
with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall('data')

print("‚úì Zip file extracted to 'data' folder!")

import os

# Function to list all files recursively
def list_files(directory, indent=0):
    items = os.listdir(directory)
    for item in sorted(items):
        item_path = os.path.join(directory, item)
        print("  " * indent + f"üìÑ {item}" if os.path.isfile(item_path) else "  " * indent + f"üìÅ {item}")
        if os.path.isdir(item_path):
            list_files(item_path, indent + 1)

print("="*60)
print("DATASET CONTENTS:")
print("="*60)
list_files('data')

import scipy.io
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the 4 discharge cycles
print("Loading discharge cycles...")

cycle1 = scipy.io.loadmat('data/Drive cycles/25degC_Cycle_1_Pan18650PF.mat')
cycle2 = scipy.io.loadmat('data/Drive cycles/25degC_Cycle_2_Pan18650PF.mat')
cycle3 = scipy.io.loadmat('data/Drive cycles/25degC_Cycle_3_Pan18650PF.mat')
cycle4 = scipy.io.loadmat('data/Drive cycles/25degC_Cycle_4_Pan18650PF.mat')

print("‚úì All 4 cycles loaded!")

# Let's see what's inside cycle 1
print("\n" + "="*60)
print("EXPLORING CYCLE 1 STRUCTURE:")
print("="*60)
print("Keys in the data:", cycle1.keys())

import os

# Check what's directly in the data folder
print("Contents of 'data' folder:")
for item in os.listdir('data'):
    print(f"  - {item}")

# Check if there's a subfolder
subfolders = [item for item in os.listdir('data') if os.path.isdir(os.path.join('data', item))]
if subfolders:
    print(f"\nLooking inside '{subfolders[0]}':")
    drive_cycles_path = os.path.join('data', subfolders[0])
    for item in os.listdir(drive_cycles_path):
        if 'Cycle' in item and '25degC' in item:
            print(f"  ‚úì {item}")

import scipy.io
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# First, let's find the correct path
base_path = 'data'
items = os.listdir(base_path)

# Find the Drive cycles folder (might have different name)
drive_folder = None
for item in items:
    if 'Drive' in item or 'drive' in item:
        drive_folder = item
        break

if drive_folder:
    cycles_path = os.path.join(base_path, drive_folder)
    print(f"Found drive cycles folder: {cycles_path}")
else:
    # If extracted directly into data folder
    cycles_path = base_path

# Load the 4 discharge cycles with correct path
print("\nLoading discharge cycles...")

cycle1 = scipy.io.loadmat(f'{cycles_path}/25degC_Cycle_1_Pan18650PF.mat')
cycle2 = scipy.io.loadmat(f'{cycles_path}/25degC_Cycle_2_Pan18650PF.mat')
cycle3 = scipy.io.loadmat(f'{cycles_path}/25degC_Cycle_3_Pan18650PF.mat')
cycle4 = scipy.io.loadmat(f'{cycles_path}/25degC_Cycle_4_Pan18650PF.mat')

print("‚úì All 4 cycles loaded successfully!")

# Explore the structure
print("\n" + "="*60)
print("EXPLORING CYCLE 1 STRUCTURE:")
print("="*60)
print("Keys:", [k for k in cycle1.keys() if not k.startswith('__')])

import os

def find_files(directory, search_term='25degC_Cycle'):
    """Find all files matching the search term"""
    matches = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if search_term in file:
                full_path = os.path.join(root, file)
                matches.append(full_path)
    return matches

# Find the cycle files
print("Searching for cycle files...")
cycle_files = find_files('data', '25degC_Cycle')

if cycle_files:
    print(f"\n‚úì Found {len(cycle_files)} cycle files:")
    for f in sorted(cycle_files):
        print(f"  {f}")
else:
    print("\n‚ùå No cycle files found. Let's see all .mat files:")
    all_mat = find_files('data', '.mat')
    for f in sorted(all_mat)[:20]:  # Show first 20
        print(f"  {f}")

import scipy.io
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Use the correct paths
base_path = 'data/Panasonic 18650PF Data/Panasonic 18650PF Data/25degC/Drive cycles/'

print("Loading discharge cycles...")

cycle1 = scipy.io.loadmat(base_path + '03-18-17_02.17 25degC_Cycle_1_Pan18650PF.mat')
cycle2 = scipy.io.loadmat(base_path + '03-19-17_03.25 25degC_Cycle_2_Pan18650PF.mat')
cycle3 = scipy.io.loadmat(base_path + '03-19-17_09.07 25degC_Cycle_3_Pan18650PF.mat')
cycle4 = scipy.io.loadmat(base_path + '03-19-17_14.31 25degC_Cycle_4_Pan18650PF.mat')

print("‚úì All 4 cycles loaded successfully!")

# Explore the structure of cycle 1
print("\n" + "="*60)
print("EXPLORING CYCLE 1 STRUCTURE:")
print("="*60)

# Show non-private keys
keys = [k for k in cycle1.keys() if not k.startswith('__')]
print("Available keys:", keys)

# Let's look at the main data structure
if keys:
    main_key = keys[0]
    print(f"\nExamining '{main_key}':")
    print(f"Type: {type(cycle1[main_key])}")
    print(f"Shape: {cycle1[main_key].shape}")

    # If it's a structured array, show field names
    if hasattr(cycle1[main_key], 'dtype') and cycle1[main_key].dtype.names:
        print(f"Fields available: {cycle1[main_key].dtype.names}")

# Extract data from all 4 cycles
def extract_cycle_data(cycle_mat):
    """Extract data from MATLAB structure"""
    data = cycle_mat['meas'][0, 0]

    df = pd.DataFrame({
        'Time': data['Time'].flatten(),
        'Voltage': data['Voltage'].flatten(),
        'Current': data['Current'].flatten(),
        'Ah': data['Ah'].flatten(),  # Ampere-hours (used to calculate SoC)
        'Temperature': data['Battery_Temp_degC'].flatten(),
    })

    return df

# Extract all 4 cycles
print("Extracting data from cycles...")
df1 = extract_cycle_data(cycle1)
df2 = extract_cycle_data(cycle2)
df3 = extract_cycle_data(cycle3)
df4 = extract_cycle_data(cycle4)

print("‚úì Data extracted successfully!")
print(f"\nCycle 1: {len(df1)} samples")
print(f"Cycle 2: {len(df2)} samples")
print(f"Cycle 3: {len(df3)} samples")
print(f"Cycle 4: {len(df4)} samples")
print(f"Total: {len(df1) + len(df2) + len(df3) + len(df4)} samples")

# Show first few rows of Cycle 1
print("\n" + "="*60)
print("CYCLE 1 - First 5 rows:")
print("="*60)
print(df1.head())

# Check data ranges
print("\n" + "="*60)
print("DATA RANGES (Cycle 1):")
print("="*60)
print(df1.describe())

# Calculate SoC for each cycle
# SoC = (Current_Ah / Max_Capacity) * 100
# For discharge: SoC goes from 100% to 0%

def calculate_soc(df, battery_capacity=2.9):  # 2.9 Ah nominal capacity
    """
    Calculate State of Charge
    For discharge cycles, we start at 100% and decrease
    """
    # Get the Ah values (they're negative for discharge)
    ah = df['Ah'].values

    # Calculate SoC (starting from 100%)
    # Since Ah is negative and decreasing, we calculate remaining capacity
    min_ah = ah.min()  # Most negative value (end of discharge)
    max_ah = ah.max()  # Least negative value (start of discharge)

    # SoC percentage based on remaining capacity
    soc = ((ah - min_ah) / (max_ah - min_ah)) * 100

    # Clip to [0, 100] range just to be safe
    soc = np.clip(soc, 0, 100)

    return soc

# Add SoC to each dataframe
print("Calculating SoC for all cycles...")
df1['SoC'] = calculate_soc(df1)
df2['SoC'] = calculate_soc(df2)
df3['SoC'] = calculate_soc(df3)
df4['SoC'] = calculate_soc(df4)

print("‚úì SoC calculated for all cycles!")

# Visualize SoC for all cycles
plt.figure(figsize=(15, 10))

# Plot SoC for all 4 cycles
plt.subplot(3, 2, 1)
plt.plot(df1['SoC'], linewidth=1.5, color='blue')
plt.title('State of Charge - Cycle 1', fontsize=12, fontweight='bold')
plt.xlabel('Sample')
plt.ylabel('SoC (%)')
plt.grid(True, alpha=0.3)
plt.ylim([-5, 105])

plt.subplot(3, 2, 2)
plt.plot(df2['SoC'], linewidth=1.5, color='green')
plt.title('State of Charge - Cycle 2', fontsize=12, fontweight='bold')
plt.xlabel('Sample')
plt.ylabel('SoC (%)')
plt.grid(True, alpha=0.3)
plt.ylim([-5, 105])

plt.subplot(3, 2, 3)
plt.plot(df3['SoC'], linewidth=1.5, color='orange')
plt.title('State of Charge - Cycle 3', fontsize=12, fontweight='bold')
plt.xlabel('Sample')
plt.ylabel('SoC (%)')
plt.grid(True, alpha=0.3)
plt.ylim([-5, 105])

plt.subplot(3, 2, 4)
plt.plot(df4['SoC'], linewidth=1.5, color='red')
plt.title('State of Charge - Cycle 4', fontsize=12, fontweight='bold')
plt.xlabel('Sample')
plt.ylabel('SoC (%)')
plt.grid(True, alpha=0.3)
plt.ylim([-5, 105])

# Plot voltage for Cycle 1
plt.subplot(3, 2, 5)
plt.plot(df1['Voltage'], linewidth=1.5, color='purple')
plt.title('Voltage - Cycle 1', fontsize=12, fontweight='bold')
plt.xlabel('Sample')
plt.ylabel('Voltage (V)')
plt.grid(True, alpha=0.3)

# Plot current for Cycle 1
plt.subplot(3, 2, 6)
plt.plot(df1['Current'], linewidth=1.5, color='brown')
plt.title('Current - Cycle 1', fontsize=12, fontweight='bold')
plt.xlabel('Sample')
plt.ylabel('Current (A)')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Show SoC statistics
print("\n" + "="*60)
print("SoC STATISTICS:")
print("="*60)
print(f"Cycle 1 - SoC range: {df1['SoC'].min():.2f}% to {df1['SoC'].max():.2f}%")
print(f"Cycle 2 - SoC range: {df2['SoC'].min():.2f}% to {df2['SoC'].max():.2f}%")
print(f"Cycle 3 - SoC range: {df3['SoC'].min():.2f}% to {df3['SoC'].max():.2f}%")
print(f"Cycle 4 - SoC range: {df4['SoC'].min():.2f}% to {df4['SoC'].max():.2f}%")

print("\n" + "="*60)
print("‚úÖ STEP 2 COMPLETE!")
print("="*60)
print(f"‚úì Loaded 4 discharge cycles")
print(f"‚úì Total samples: {len(df1) + len(df2) + len(df3) + len(df4):,}")
print(f"‚úì SoC calculated for all cycles")
print(f"‚úì Data looks good and ready for preprocessing!")

from sklearn.preprocessing import MinMaxScaler

# Combine all 4 cycles
print("Combining all 4 discharge cycles...")
all_data = pd.concat([df1, df2, df3, df4], ignore_index=True)

print(f"‚úì Combined data shape: {all_data.shape}")
print(f"‚úì Total samples: {len(all_data):,}")

# Extract SoC column (our target variable)
soc_data = all_data['SoC'].values

print(f"\nSoC data shape: {soc_data.shape}")
print(f"SoC range: {soc_data.min():.2f}% to {soc_data.max():.2f}%")

# Convert to 0-1 range (from 0-100%)
soc_data = soc_data / 100.0
print(f"After scaling: {soc_data.min():.4f} to {soc_data.max():.4f}")

# Reshape for scaler (needs 2D array)
soc_data = soc_data.reshape(-1, 1)

# Normalize using MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))
soc_scaled = scaler.fit_transform(soc_data)

print(f"\n‚úì Data normalized")
print(f"Scaled SoC shape: {soc_scaled.shape}")
print(f"Scaled SoC range: {soc_scaled.min():.4f} to {soc_scaled.max():.4f}")

def create_sequences(data, look_back=60):
    """
    Create sequences for LSTM input
    Input: data of shape (n_samples, 1)
    Output: X of shape (n_samples, look_back, 1), y of shape (n_samples,)
    """
    X, y = [], []
    for i in range(len(data) - look_back):
        # Take previous 60 time steps as features
        X.append(data[i:(i + look_back), 0])
        # Predict the next time step
        y.append(data[i + look_back, 0])

    return np.array(X), np.array(y)

# Create sequences with look_back = 60
LOOK_BACK = 60
print(f"Creating sequences with look_back = {LOOK_BACK}...")

X, y = create_sequences(soc_scaled, LOOK_BACK)

print(f"\n‚úì Sequences created!")
print(f"X shape: {X.shape}")  # Should be (n_samples, 60)
print(f"y shape: {y.shape}")  # Should be (n_samples,)

# Reshape X for LSTM: (samples, time_steps, features)
X = X.reshape(X.shape[0], X.shape[1], 1)
print(f"X reshaped for LSTM: {X.shape}")  # Should be (n_samples, 60, 1)

# Split into train and validation sets (80/20)
# Important: Don't shuffle time series data!
split_ratio = 0.8
split_index = int(len(X) * split_ratio)

X_train = X[:split_index]
y_train = y[:split_index]
X_val = X[split_index:]
y_val = y[split_index:]

print("\n" + "="*60)
print("TRAIN/VALIDATION SPLIT:")
print("="*60)
print(f"Training samples:   {X_train.shape[0]:,} ({split_ratio:.0%})")
print(f"Validation samples: {X_val.shape[0]:,} ({1-split_ratio:.0%})")
print(f"Total samples:      {len(X):,}")

print(f"\nX_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_val shape:   {X_val.shape}")
print(f"y_val shape:   {y_val.shape}")

print("\n" + "="*60)
print("‚úÖ STEP 3 COMPLETE!")
print("="*60)
print("‚úì Data combined from all 4 cycles")
print("‚úì SoC normalized to [0, 1] range")
print("‚úì Sequences created with look_back=60")
print("‚úì Train/validation split: 80/20")
print("‚úì Data ready for model training!")

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Paper's exact specifications
LOOK_BACK = 60
HIDDEN_DIM = 5  # Just 5 LSTM units - keep it simple!
LEARNING_RATE = 0.1
EPOCHS = 100
BATCH_SIZE = 60

print("="*60)
print("MODEL HYPERPARAMETERS (from paper):")
print("="*60)
print(f"Look-back:      {LOOK_BACK}")
print(f"Hidden units:   {HIDDEN_DIM}")
print(f"Learning rate:  {LEARNING_RATE}")
print(f"Epochs:         {EPOCHS}")
print(f"Batch size:     {BATCH_SIZE}")
print("="*60)

def build_lstm_model():
    """Build LSTM model matching paper specifications"""
    model = keras.Sequential([
        # Input: (batch, 60, 1)
        layers.Input(shape=(LOOK_BACK, 1)),

        # LSTM layer with 5 units
        layers.LSTM(HIDDEN_DIM, return_sequences=False),

        # Output layer with sigmoid activation
        layers.Dense(1, activation='sigmoid')
    ], name='LSTM_SoC_Predictor')

    return model

# Create the model
model = build_lstm_model()

# Display architecture
print("\n" + "="*60)
print("MODEL ARCHITECTURE:")
print("="*60)
model.summary()

# Compile with MSE loss
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='mse',  # Mean Squared Error
    metrics=['mae']  # Mean Absolute Error for monitoring
)

print("\n‚úì Model compiled successfully!")
print(f"‚úì Optimizer: Adam with LR={LEARNING_RATE}")
print(f"‚úì Loss function: MSE")
print(f"‚úì Trainable parameters: {model.count_params():,}")

import time

print("="*60)
print("STARTING TRAINING...")
print("="*60)
print(f"Training samples: {X_train.shape[0]:,}")
print(f"Validation samples: {X_val.shape[0]:,}")
print(f"Epochs: {EPOCHS}")
print(f"Batch size: {BATCH_SIZE}")
print("="*60)

# Record start time
start_time = time.time()

# Train the model
history = model.fit(
    X_train, y_train,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    validation_data=(X_val, y_val),
    verbose=1
)

# Calculate training time
training_time = time.time() - start_time
minutes = int(training_time // 60)
seconds = int(training_time % 60)

print("\n" + "="*60)
print("TRAINING COMPLETE!")
print("="*60)
print(f"Training time: {minutes} minutes {seconds} seconds")
print("="*60)

# Rebuild model with LOWER learning rate
LEARNING_RATE = 0.001  # Much more stable (100x smaller)

# Rebuild the model
model = build_lstm_model()

# Compile with lower learning rate
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='mse',
    metrics=['mae']
)

print(f"‚úì Model rebuilt with learning_rate = {LEARNING_RATE}")

import time

print("="*60)
print("RETRAINING WITH STABLE LEARNING RATE...")
print("="*60)

start_time = time.time()

history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=60,
    validation_data=(X_val, y_val),
    verbose=1
)

training_time = time.time() - start_time
minutes = int(training_time // 60)
seconds = int(training_time % 60)

print(f"\nTraining time: {minutes} minutes {seconds} seconds")

from tensorflow.keras.callbacks import EarlyStopping

# Rebuild model with lower learning rate
LEARNING_RATE = 0.001

model = build_lstm_model()
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='mse',
    metrics=['mae']
)

# Early stopping: stop if validation loss doesn't improve for 10 epochs
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True,
    verbose=1
)

print("‚úì Model ready with early stopping")
print(f"‚úì Will stop if no improvement for 10 epochs")

import time

print("="*60)
print("TRAINING WITH EARLY STOPPING...")
print("="*60)

start_time = time.time()

history = model.fit(
    X_train, y_train,
    epochs=100,  # Max epochs, but will likely stop earlier
    batch_size=60,
    validation_data=(X_val, y_val),
    callbacks=[early_stop],
    verbose=1
)

training_time = time.time() - start_time
minutes = int(training_time // 60)
seconds = int(training_time % 60)

print(f"\n‚úì Training stopped at epoch: {len(history.history['loss'])}")
print(f"‚úì Total time: {minutes} minutes {seconds} seconds")

import numpy as np

print("="*60)
print("CALCULATING RMSE...")
print("="*60)

# Make predictions
print("Making predictions on training set...")
y_train_pred = model.predict(X_train, verbose=0)

print("Making predictions on validation set...")
y_val_pred = model.predict(X_val, verbose=0)

# Calculate RMSE on normalized scale (0-1)
def calculate_rmse(y_true, y_pred):
    """Calculate Root Mean Squared Error"""
    mse = np.mean((y_true - y_pred) ** 2)
    rmse = np.sqrt(mse)
    return rmse

# RMSE on normalized scale (0-1)
train_rmse_normalized = calculate_rmse(y_train, y_train_pred)
val_rmse_normalized = calculate_rmse(y_val, y_val_pred)

# RMSE on percentage scale (0-100%)
# Multiply by 100 to convert back to percentage
train_rmse_percentage = train_rmse_normalized * 100
val_rmse_percentage = val_rmse_normalized * 100

print("\n" + "="*60)
print("FINAL RESULTS - OUR MODEL")
print("="*60)
print(f"Training RMSE (normalized):   {train_rmse_normalized:.6f}")
print(f"Validation RMSE (normalized): {val_rmse_normalized:.6f}")
print()
print(f"Training RMSE (percentage):   {train_rmse_percentage:.4f}%")
print(f"Validation RMSE (percentage): {val_rmse_percentage:.4f}%")

print("\n" + "="*60)
print("PAPER'S RESULTS")
print("="*60)
print(f"Training RMSE:   0.3438")
print(f"Validation RMSE: 0.3681")

print("\n" + "="*60)
print("COMPARISON")
print("="*60)
print(f"Our Training RMSE:   {train_rmse_percentage:.4f}% vs Paper: 0.3438")
print(f"Our Validation RMSE: {val_rmse_percentage:.4f}% vs Paper: 0.3681")

# Calculate MAE as well
train_mae = np.mean(np.abs(y_train - y_train_pred)) * 100
val_mae = np.mean(np.abs(y_val - y_val_pred)) * 100

print(f"\nBonus - MAE:")
print(f"Training MAE:   {train_mae:.4f}%")
print(f"Validation MAE: {val_mae:.4f}%")
print("="*60)

# Check if model exists
try:
    print(model.summary())
    print("‚úì Model exists!")
except:
    print("‚ùå Model not found - need to rebuild")

# Rebuild the model architecture
from tensorflow import keras
from tensorflow.keras import layers

LOOK_BACK = 60
HIDDEN_DIM = 5

def build_lstm_model():
    model = keras.Sequential([
        layers.Input(shape=(LOOK_BACK, 1)),
        layers.LSTM(HIDDEN_DIM, return_sequences=False),
        layers.Dense(1, activation='sigmoid')
    ], name='LSTM_SoC_Predictor')
    return model

model = build_lstm_model()
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)

print("‚úì Model architecture rebuilt!")
model.summary()

# Try to use the weights from the training session
try:
    # If history exists, we can see what epoch we trained to
    print(f"Training completed {len(history.history['loss'])} epochs")
    print("‚úì History exists - but weights were lost")
    print("\n‚ö†Ô∏è We need to retrain the model")
    need_retrain = True
except:
    print("‚ùå History also missing")
    need_retrain = True

if need_retrain:
    print("\n" + "="*60)
    print("SOLUTION: Quick Retrain")
    print("="*60)
    print("Don't worry - retraining will be much faster now!")
    print("We know it works and will stop at ~40 epochs")
    print("Expected time: ~80-90 minutes")
    print("="*60)

# Check if data still exists
try:
    print(f"‚úì X_train shape: {X_train.shape}")
    print(f"‚úì X_val shape: {X_val.shape}")
    print(f"‚úì y_train shape: {y_train.shape}")
    print(f"‚úì y_val shape: {y_val.shape}")
    print("\n‚úì‚úì GOOD NEWS: Data still exists!")
    print("We can retrain immediately!")
    data_exists = True
except:
    print("‚ùå Data also missing")
    print("Need to reload everything from the beginning")
    data_exists = False

import scipy.io
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

print("="*60)
print("STEP 1: LOADING DATA")
print("="*60)

# Define the correct path
base_path = 'data/Panasonic 18650PF Data/Panasonic 18650PF Data/25degC/Drive cycles/'

# Load the 4 discharge cycles
print("Loading discharge cycles...")
cycle1 = scipy.io.loadmat(base_path + '03-18-17_02.17 25degC_Cycle_1_Pan18650PF.mat')
cycle2 = scipy.io.loadmat(base_path + '03-19-17_03.25 25degC_Cycle_2_Pan18650PF.mat')
cycle3 = scipy.io.loadmat(base_path + '03-19-17_09.07 25degC_Cycle_3_Pan18650PF.mat')
cycle4 = scipy.io.loadmat(base_path + '03-19-17_14.31 25degC_Cycle_4_Pan18650PF.mat')
print("‚úì All 4 cycles loaded!")

# Extract data function
def extract_cycle_data(cycle_mat):
    data = cycle_mat['meas'][0, 0]
    df = pd.DataFrame({
        'Time': data['Time'].flatten(),
        'Voltage': data['Voltage'].flatten(),
        'Current': data['Current'].flatten(),
        'Ah': data['Ah'].flatten(),
        'Temperature': data['Battery_Temp_degC'].flatten(),
    })
    return df

# Extract all cycles
df1 = extract_cycle_data(cycle1)
df2 = extract_cycle_data(cycle2)
df3 = extract_cycle_data(cycle3)
df4 = extract_cycle_data(cycle4)

print(f"‚úì Cycle 1: {len(df1)} samples")
print(f"‚úì Cycle 2: {len(df2)} samples")
print(f"‚úì Cycle 3: {len(df3)} samples")
print(f"‚úì Cycle 4: {len(df4)} samples")

# Calculate SoC
def calculate_soc(df):
    ah = df['Ah'].values
    min_ah = ah.min()
    max_ah = ah.max()
    soc = ((ah - min_ah) / (max_ah - min_ah)) * 100
    soc = np.clip(soc, 0, 100)
    return soc

df1['SoC'] = calculate_soc(df1)
df2['SoC'] = calculate_soc(df2)
df3['SoC'] = calculate_soc(df3)
df4['SoC'] = calculate_soc(df4)

print("‚úì SoC calculated for all cycles!")
print("\n‚úÖ STEP 1 COMPLETE - Data loaded!")

print("="*60)
print("STEP 2: PREPROCESSING")
print("="*60)

# Combine all cycles
all_data = pd.concat([df1, df2, df3, df4], ignore_index=True)
print(f"‚úì Combined: {len(all_data):,} samples")

# Extract and normalize SoC
soc_data = all_data['SoC'].values / 100.0  # Convert to 0-1
soc_data = soc_data.reshape(-1, 1)

# Scale
scaler = MinMaxScaler(feature_range=(0, 1))
soc_scaled = scaler.fit_transform(soc_data)
print(f"‚úì Data normalized: {soc_scaled.min():.4f} to {soc_scaled.max():.4f}")

# Create sequences
def create_sequences(data, look_back=60):
    X, y = [], []
    for i in range(len(data) - look_back):
        X.append(data[i:(i + look_back), 0])
        y.append(data[i + look_back, 0])
    return np.array(X), np.array(y)

LOOK_BACK = 60
X, y = create_sequences(soc_scaled, LOOK_BACK)
X = X.reshape(X.shape[0], X.shape[1], 1)

print(f"‚úì Sequences created: X shape {X.shape}")

# Train/val split (80/20)
split_ratio = 0.8
split_index = int(len(X) * split_ratio)

X_train = X[:split_index]
y_train = y[:split_index]
X_val = X[split_index:]
y_val = y[split_index:]

print(f"‚úì Training: {X_train.shape[0]:,} samples")
print(f"‚úì Validation: {X_val.shape[0]:,} samples")
print("\n‚úÖ STEP 2 COMPLETE - Data preprocessed!")

print("="*60)
print("STEP 3: BUILD MODEL AND TRAIN")
print("="*60)

# Create models folder
os.makedirs('models', exist_ok=True)

# Model parameters
HIDDEN_DIM = 5
LEARNING_RATE = 0.001
EPOCHS = 100
BATCH_SIZE = 60

# Build model
def build_lstm_model():
    model = keras.Sequential([
        layers.Input(shape=(LOOK_BACK, 1)),
        layers.LSTM(HIDDEN_DIM, return_sequences=False),
        layers.Dense(1, activation='sigmoid')
    ], name='LSTM_SoC_Predictor')
    return model

model = build_lstm_model()
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='mse',
    metrics=['mae']
)

print("‚úì Model built!")
model.summary()

# Callbacks
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True,
    verbose=1
)

# Model checkpoint - saves best model automatically!
checkpoint = ModelCheckpoint(
    'models/best_model.keras',
    monitor='val_loss',
    save_best_only=True,
    verbose=1
)

print("\n" + "="*60)
print("STARTING TRAINING...")
print("="*60)
print(f"‚úì Model will autosave to: models/best_model.keras")
print(f"‚úì Early stopping enabled (patience=10)")
print("="*60)

import time
start_time = time.time()

# Train
history = model.fit(
    X_train, y_train,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    validation_data=(X_val, y_val),
    callbacks=[early_stop, checkpoint],
    verbose=1
)

training_time = time.time() - start_time
minutes = int(training_time // 60)
seconds = int(training_time % 60)

print("\n" + "="*60)
print("‚úÖ TRAINING COMPLETE!")
print("="*60)
print(f"‚úì Epochs completed: {len(history.history['loss'])}")
print(f"‚úì Training time: {minutes} min {seconds} sec")
print(f"‚úì Model saved to: models/best_model.keras")
print("="*60)

"""
STEP 4: MODEL EVALUATION AND VISUALIZATION
Run this immediately after training completes!
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import seaborn as sns

print("="*60)
print("STEP 4: EVALUATE MODEL PERFORMANCE")
print("="*60)

# ============================================================
# 1. LOAD BEST MODEL (automatically saved during training)
# ============================================================
from tensorflow import keras

best_model = keras.models.load_model('models/best_model.keras')
print("‚úì Best model loaded from: models/best_model.keras")

# ============================================================
# 2. MAKE PREDICTIONS
# ============================================================
print("\n" + "="*60)
print("MAKING PREDICTIONS...")
print("="*60)

y_train_pred = best_model.predict(X_train, verbose=0)
y_val_pred = best_model.predict(X_val, verbose=0)

# ============================================================
# 3. CALCULATE METRICS (Compare with Paper's Results)
# ============================================================
print("\n" + "="*60)
print("PERFORMANCE METRICS")
print("="*60)

# Training metrics
train_mse = mean_squared_error(y_train, y_train_pred)
train_rmse = np.sqrt(train_mse)
train_mae = mean_absolute_error(y_train, y_train_pred)

# Validation metrics
val_mse = mean_squared_error(y_val, y_val_pred)
val_rmse = np.sqrt(val_mse)
val_mae = mean_absolute_error(y_val, y_val_pred)

print(f"\nüìä TRAINING SET:")
print(f"   MSE:  {train_mse:.6f}")
print(f"   RMSE: {train_rmse:.6f} ({train_rmse*100:.4f}%)")
print(f"   MAE:  {train_mae:.6f} ({train_mae*100:.4f}%)")

print(f"\nüìä VALIDATION SET:")
print(f"   MSE:  {val_mse:.6f}")
print(f"   RMSE: {val_rmse:.6f} ({val_rmse*100:.4f}%)")
print(f"   MAE:  {val_mae:.6f} ({val_mae*100:.4f}%)")

print(f"\nüéØ PAPER'S TARGET:")
print(f"   Training RMSE:   0.3438 (34.38%)")
print(f"   Validation RMSE: 0.3681 (36.81%)")

print(f"\n{'='*60}")
if val_rmse < 0.3681:
    print("üéâ CONGRATULATIONS! You BEAT the paper's results!")
else:
    print("üìà Good progress! Try the advanced puzzles to improve.")
print("="*60)

# ============================================================
# 4. VISUALIZATIONS
# ============================================================
print("\n" + "="*60)
print("GENERATING VISUALIZATIONS...")
print("="*60)

fig = plt.figure(figsize=(16, 10))

# -------------------- Plot 1: Training History --------------------
ax1 = plt.subplot(2, 3, 1)
plt.plot(history.history['loss'], label='Training Loss', linewidth=2)
plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Loss (MSE)', fontsize=12)
plt.title('Training and Validation Loss', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.yscale('log')  # Log scale to see small values

# -------------------- Plot 2: MAE History --------------------
ax2 = plt.subplot(2, 3, 2)
plt.plot(history.history['mae'], label='Training MAE', linewidth=2)
plt.plot(history.history['val_mae'], label='Validation MAE', linewidth=2)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('MAE', fontsize=12)
plt.title('Mean Absolute Error', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# -------------------- Plot 3: Predictions vs Actual (Validation) --------------------
ax3 = plt.subplot(2, 3, 3)
plt.scatter(y_val, y_val_pred, alpha=0.5, s=10)
plt.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfect Prediction')
plt.xlabel('Actual SoC', fontsize=12)
plt.ylabel('Predicted SoC', fontsize=12)
plt.title('Validation: Predicted vs Actual', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.xlim([0, 1])
plt.ylim([0, 1])

# Add R¬≤ score
r2 = r2_score(y_val, y_val_pred)
plt.text(0.05, 0.95, f'R¬≤ = {r2:.6f}', transform=ax3.transAxes,
         fontsize=11, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

# -------------------- Plot 4: Error Distribution --------------------
ax4 = plt.subplot(2, 3, 4)
errors = y_val - y_val_pred.flatten()
plt.hist(errors, bins=50, edgecolor='black', alpha=0.7)
plt.xlabel('Prediction Error', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.title('Error Distribution (Validation)', fontsize=14, fontweight='bold')
plt.axvline(x=0, color='r', linestyle='--', linewidth=2)
plt.grid(True, alpha=0.3)
plt.text(0.05, 0.95, f'Mean Error: {errors.mean():.6f}\nStd: {errors.std():.6f}',
         transform=ax4.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))

# -------------------- Plot 5: Time Series Predictions (Sample) --------------------
ax5 = plt.subplot(2, 3, 5)
# Show first 500 predictions
n_samples = min(500, len(y_val))
plt.plot(y_val[:n_samples], label='Actual', linewidth=2, alpha=0.7)
plt.plot(y_val_pred[:n_samples], label='Predicted', linewidth=2, alpha=0.7)
plt.xlabel('Sample Index', fontsize=12)
plt.ylabel('SoC', fontsize=12)
plt.title('Time Series: First 500 Samples', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# -------------------- Plot 6: Error by SoC Range --------------------
ax6 = plt.subplot(2, 3, 6)
# Bin errors by SoC range
soc_bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]
bin_labels = ['0-20%', '20-40%', '40-60%', '60-80%', '80-100%']
y_val_binned = np.digitize(y_val, soc_bins) - 1

mae_by_bin = []
for i in range(len(bin_labels)):
    mask = y_val_binned == i
    if mask.sum() > 0:
        mae_bin = mean_absolute_error(y_val[mask], y_val_pred[mask])
        mae_by_bin.append(mae_bin * 100)  # Convert to percentage
    else:
        mae_by_bin.append(0)

bars = plt.bar(bin_labels, mae_by_bin, color='skyblue', edgecolor='black')
plt.xlabel('SoC Range', fontsize=12)
plt.ylabel('MAE (%)', fontsize=12)
plt.title('Error by SoC Range (Critical: <20%)', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3, axis='y')

# Highlight low SoC region
bars[0].set_color('salmon')

plt.tight_layout()
plt.savefig('models/training_results.png', dpi=300, bbox_inches='tight')
print("‚úì Plots saved to: models/training_results.png")
plt.show()

# ============================================================
# 5. DETAILED ANALYSIS FOR LOW SoC (<20%)
# ============================================================
print("\n" + "="*60)
print("CRITICAL REGION ANALYSIS (SoC < 20%)")
print("="*60)

low_soc_mask = y_val < 0.2
if low_soc_mask.sum() > 0:
    low_soc_rmse = np.sqrt(mean_squared_error(y_val[low_soc_mask], y_val_pred[low_soc_mask]))
    low_soc_mae = mean_absolute_error(y_val[low_soc_mask], y_val_pred[low_soc_mask])

    print(f"üìä Low SoC Region (<20%):")
    print(f"   Samples: {low_soc_mask.sum()}")
    print(f"   RMSE: {low_soc_rmse:.6f} ({low_soc_rmse*100:.4f}%)")
    print(f"   MAE:  {low_soc_mae:.6f} ({low_soc_mae*100:.4f}%)")
    print(f"\n‚ö†Ô∏è  This is CRITICAL for BMS - accuracy at low SoC prevents battery damage!")
else:
    print("‚ö†Ô∏è  No samples in low SoC region (<20%)")

# ============================================================
# 6. SUMMARY AND RECOMMENDATIONS
# ============================================================
print("\n" + "="*60)
print("SUMMARY & NEXT STEPS")
print("="*60)

print(f"\n‚úÖ Model Performance:")
print(f"   - Validation RMSE: {val_rmse*100:.4f}%")
print(f"   - Validation MAE:  {val_mae*100:.4f}%")
print(f"   - R¬≤ Score: {r2:.6f}")

print(f"\nüìÅ Saved Files:")
print(f"   - Best model: models/best_model.keras")
print(f"   - Visualizations: models/training_results.png")

print(f"\nüéØ Recommendations:")
if val_rmse > 0.01:  # If RMSE > 1%
    print("   1. Try Level 3: Custom weighted loss for low SoC")
    print("   2. Try Level 5: Add voltage, current, temperature features")
    print("   3. Try Level 6: Stacked LSTM architecture")
elif val_rmse > 0.001:  # If RMSE > 0.1%
    print("   1. Try Level 7: Quantization for FPGA deployment")
    print("   2. Try Level 8: Ensemble for uncertainty estimation")
else:
    print("   üéâ Excellent! Ready for FPGA deployment (Level 7)")
    print("   Consider Level 8 for production-grade uncertainty estimates")

print("\n" + "="*60)
print("EVALUATION COMPLETE!")
print("="*60)

"""
PROPER TEST: Unseen Drive Cycle Evaluation
This tests if your model truly generalizes to NEW driving patterns!
"""

import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt

print("="*60)
print("PROPER GENERALIZATION TEST")
print("="*60)

# ============================================================
# 1. CHECK YOUR DATA SPLIT
# ============================================================
print("\nüìã CURRENT DATA SPLIT ANALYSIS:")
print("="*60)

# Check if you have cycle information
# If your data has a 'cycle' or 'file_id' column, we can verify proper splitting

# Example: Let's check how your data was split
print(f"Training samples: {len(X_train)}")
print(f"Validation samples: {len(X_val)}")
print(f"Split ratio: {len(X_train)/(len(X_train)+len(X_val))*100:.1f}% train")

# ============================================================
# 2. LOAD ORIGINAL DATA AND CREATE PROPER SPLIT
# ============================================================
print("\n‚ö†Ô∏è  IMPORTANT: Proper Test Setup")
print("="*60)
print("The paper uses:")
print("  - Train: Cycles 1, 2, 3 (multiple drive patterns)")
print("  - Test:  Cycle 4 (completely UNSEEN drive pattern)")
print("\nThis tests if the model can generalize to NEW driving behavior!")

# If you have the original CSV files, let's do a proper split
print("\nüîç To verify true generalization, we need to:")
print("   1. Load all 4 drive cycles separately")
print("   2. Train on cycles 1-3")
print("   3. Test ONLY on cycle 4")

# ============================================================
# 3. SAMPLE CODE FOR PROPER CYCLE-BASED SPLIT
# ============================================================
print("\n" + "="*60)
print("RECOMMENDED: Cycle-Based Split Code")
print("="*60)

sample_code = '''
# Load your data with cycle information
# Assuming you have files like: cycle_1.csv, cycle_2.csv, etc.

import pandas as pd
import numpy as np

# Load all cycles
cycle_1 = pd.read_csv('path/to/cycle_1.csv')
cycle_2 = pd.read_csv('path/to/cycle_2.csv')
cycle_3 = pd.read_csv('path/to/cycle_3.csv')
cycle_4 = pd.read_csv('path/to/cycle_4.csv')

# Combine training cycles (1, 2, 3)
train_data = pd.concat([cycle_1, cycle_2, cycle_3], ignore_index=True)

# Test on completely unseen cycle 4
test_data = cycle_4.copy()

print(f"Training on cycles 1-3: {len(train_data)} samples")
print(f"Testing on cycle 4: {len(test_data)} samples")

# Now create sequences from these splits
def create_sequences(data, look_back=60):
    X, y = [], []
    for i in range(len(data) - look_back):
        X.append(data[i:i+look_back])
        y.append(data[i+look_back])
    return np.array(X), np.array(y)

X_train, y_train = create_sequences(train_data['SoC'].values, LOOK_BACK)
X_test, y_test = create_sequences(test_data['SoC'].values, LOOK_BACK)

# Reshape for LSTM
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Now train and test with this proper split!
'''

print(sample_code)

# ============================================================
# 4. SIMULATE "UNSEEN DATA" TEST
# ============================================================
print("\n" + "="*60)
print("QUICK CHECK: Test on Last 20% (Simulated Unseen)")
print("="*60)

# Let's take the last 20% of validation set as "truly unseen"
split_point = int(len(y_val) * 0.8)
y_val_seen = y_val[:split_point]
y_val_unseen = y_val[split_point:]
y_pred_seen = y_val_pred[:split_point]
y_pred_unseen = y_val_pred[split_point:]

# Metrics on "unseen" portion
unseen_rmse = np.sqrt(mean_squared_error(y_val_unseen, y_pred_unseen))
unseen_mae = mean_absolute_error(y_val_unseen, y_pred_unseen)
unseen_r2 = r2_score(y_val_unseen, y_pred_unseen)

print(f"\nüìä 'Unseen' Data Performance:")
print(f"   RMSE: {unseen_rmse:.6f} ({unseen_rmse*100:.4f}%)")
print(f"   MAE:  {unseen_mae:.6f} ({unseen_mae*100:.4f}%)")
print(f"   R¬≤:   {unseen_r2:.6f}")

# ============================================================
# 5. REALISTIC EXPECTATIONS
# ============================================================
print("\n" + "="*60)
print("REALISTIC PERFORMANCE EXPECTATIONS")
print("="*60)
print("""
üìö Based on the paper and real-world BMS:

‚úÖ EXCELLENT (Production Ready):
   - RMSE: 1-3%
   - MAE: < 2%
   - Works on unseen drive cycles

‚ö†Ô∏è  GOOD (Needs Validation):
   - RMSE: 3-5%
   - MAE: 2-4%
   - May need more training data

‚ùå NEEDS WORK:
   - RMSE: > 5%
   - Poor generalization to new patterns

üéØ YOUR CURRENT RESULT: 0.01% RMSE
   This is PERFECT for your current data split, but:
   - If it's >5% on unseen cycles ‚Üí Normal & expected!
   - If it stays <1% on unseen cycles ‚Üí Truly exceptional!
""")

# ============================================================
# 6. VISUALIZATION: Train vs Val Distribution
# ============================================================
print("\n" + "="*60)
print("DATA DISTRIBUTION ANALYSIS")
print("="*60)

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Training data distribution
axes[0].hist(y_train.flatten(), bins=50, alpha=0.7, color='blue', edgecolor='black')
axes[0].set_xlabel('SoC Value', fontsize=12)
axes[0].set_ylabel('Frequency', fontsize=12)
axes[0].set_title('Training Data Distribution', fontsize=14, fontweight='bold')
axes[0].grid(True, alpha=0.3)

# Plot 2: Validation data distribution
axes[1].hist(y_val.flatten(), bins=50, alpha=0.7, color='green', edgecolor='black')
axes[1].set_xlabel('SoC Value', fontsize=12)
axes[1].set_ylabel('Frequency', fontsize=12)
axes[1].set_title('Validation Data Distribution', fontsize=14, fontweight='bold')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('models/data_distribution.png', dpi=300, bbox_inches='tight')
print("‚úì Distribution plots saved to: models/data_distribution.png")
plt.show()

# Check if distributions are similar (indicates potential data leakage)
from scipy import stats
ks_statistic, p_value = stats.ks_2samp(y_train.flatten(), y_val.flatten())
print(f"\nüìä Distribution Similarity Test (KS Test):")
print(f"   KS Statistic: {ks_statistic:.4f}")
print(f"   P-value: {p_value:.4f}")
if p_value > 0.05:
    print("   ‚ö†Ô∏è  Distributions are VERY similar - might indicate data leakage!")
else:
    print("   ‚úÖ Distributions are different - good sign!")

# ============================================================
# 7. FINAL RECOMMENDATIONS
# ============================================================
print("\n" + "="*60)
print("üéØ NEXT STEPS FOR YOUR PROJECT")
print("="*60)
print("""
1Ô∏è‚É£  VERIFY YOUR DATA SPLIT:
    - Check if train/val come from different drive cycles
    - If mixed together ‚Üí explains perfect performance
    - If properly split ‚Üí you've achieved something amazing!

2Ô∏è‚É£  IF PROPERLY SPLIT (congrats!):
    ‚úÖ Move to Level 7: FPGA Quantization
    ‚úÖ Move to Level 8: Uncertainty Estimation
    ‚úÖ Write your paper! üìù

3Ô∏è‚É£  IF NOT PROPERLY SPLIT (normal!):
    - Re-run with cycle-based split using code above
    - Expect RMSE to increase to 1-5% range
    - Still beats the paper if you get <34%!

4Ô∏è‚É£  FOR YOUR PROJECT REPORT:
    - Document your data split strategy
    - Show train/val from different cycles
    - Compare with paper's methodology
""")

print("\n" + "="*60)
print("GENERALIZATION TEST COMPLETE!")
print("="*60)